#!/usr/bin/env python3
"""
Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ñ†ĞµĞ½Ğ·ÑƒÑ€Ğ° Ğ¼Ğ°Ñ‚Ğ° Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ c GPU-ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸ĞµĞ¼ (RTX 4060).

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ faster-whisper (CTranslate2) Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ â€”
Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ² 4-6 Ñ€Ğ°Ğ· Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Whisper.

Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:
    pip install faster-whisper numpy soundfile --break-system-packages
    # ffmpeg Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ² PATH

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
    python censor.py video.mkv
    python censor.py video.mkv --model large-v3
    python censor.py video.mkv --tracks 0,2
    python censor.py video.mkv --beep          # Ğ±Ğ¸Ğ¿ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹
    python censor.py video.mkv --info          # Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸
"""

import argparse
import hashlib
import json
import subprocess
import sys
import shutil
import re
import numpy as np
from pathlib import Path
from dataclasses import dataclass
from typing import Optional
from concurrent.futures import ThreadPoolExecutor

# Ğ›ĞµĞ½Ğ¸Ğ²Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ faster-whisper (Ğ´Ğ»Ñ --info Ğ±ĞµĞ· Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸)
WhisperModel = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEFAULT_MODEL = "medium"  # tiny, base, small, medium, large-v2, large-v3
SILENCE_THRESHOLD_DB = -50
BEEP_FREQ = 1000  # Ğ“Ñ†
PADDING_MS = 50  # Ñ€Ğ°ÑÑˆĞ¸Ñ€Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ğ·ÑƒÑ€Ñƒ Ğ½Ğ° X Ğ¼Ñ Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹

# Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
AUDIO_EXTENSIONS = {'.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.wma', '.opus'}
VIDEO_EXTENSIONS = {'.mkv', '.mp4', '.avi', '.mov', '.webm', '.ts', '.m2ts', '.wmv'}

# ĞŸÑƒÑ‚Ğ¸
SCRIPT_DIR = Path(__file__).parent
SWEARS_FILE = SCRIPT_DIR / "swears.txt"
SWEARS_FILE_ALT = Path.home() / ".config" / "censor" / "swears.txt"
CACHE_DIR = SCRIPT_DIR / "cache"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ« Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AudioTrack:
    stream_index: int
    audio_index: int
    codec: str
    channels: int
    sample_rate: int
    title: str


@dataclass
class SwearMatch:
    start: float  # ÑĞµĞºÑƒĞ½Ğ´Ñ‹
    end: float
    word: str


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ£Ğ¢Ğ˜Ğ›Ğ˜Ğ¢Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def log(msg: str, prefix: str = ""):
    print(f"{prefix}{msg}")


def print_progress(current: float, total: float, prefix: str = "", width: int = 30):
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€ Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸."""
    if total <= 0:
        return
    pct = min(current / total, 1.0)
    filled = int(width * pct)
    bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
    print(f"\r{prefix} [{bar}] {pct*100:.0f}%", end='', flush=True)
    if current >= total:
        print()


def is_audio_file(path: Path) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ„Ğ°Ğ¹Ğ» Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ¼."""
    return path.suffix.lower() in AUDIO_EXTENSIONS


def is_video_file(path: Path) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ„Ğ°Ğ¹Ğ» Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ¼."""
    return path.suffix.lower() in VIDEO_EXTENSIONS


def get_audio_duration(path: Path) -> float:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…."""
    cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", str(path)]
    result = run_cmd(cmd, capture=True)
    if result.returncode != 0:
        return 0
    try:
        info = json.loads(result.stdout)
        return float(info.get("format", {}).get("duration", 0))
    except (ValueError, KeyError):
        return 0


def run_cmd(cmd: list[str], capture: bool = False, quiet: bool = True) -> subprocess.CompletedProcess:
    """Ğ—Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº."""
    try:
        if capture:
            return subprocess.run(cmd, capture_output=True, text=True)
        elif quiet:
            return subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        else:
            return subprocess.run(cmd)
    except FileNotFoundError:
        print(f"âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {cmd[0]}")
        sys.exit(1)


def run_ffmpeg_with_progress(cmd: list[str], duration: float, prefix: str = "") -> bool:
    """Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ ffmpeg Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°."""
    if duration <= 0:
        # Ğ‘ĞµĞ· Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°
        return run_cmd(cmd, quiet=True).returncode == 0

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°
    cmd_with_progress = cmd.copy()
    # Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»Ğµ ffmpeg Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ¼
    insert_pos = 1
    cmd_with_progress.insert(insert_pos, "-progress")
    cmd_with_progress.insert(insert_pos + 1, "pipe:1")

    try:
        process = subprocess.Popen(
            cmd_with_progress,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True
        )

        current_time = 0.0
        for line in process.stdout:
            line = line.strip()
            if line.startswith("out_time_ms="):
                try:
                    time_ms = int(line.split("=")[1])
                    current_time = time_ms / 1_000_000  # Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñ‹
                    print_progress(current_time, duration, prefix)
                except ValueError:
                    pass
            elif line == "progress=end":
                print_progress(duration, duration, prefix)

        process.wait()
        return process.returncode == 0

    except FileNotFoundError:
        print(f"âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: ffmpeg")
        return False


def get_file_hash(path: Path) -> str:
    """Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ñ…ĞµÑˆ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    stat = path.stat()
    data = f"{path.name}_{stat.st_size}_{stat.st_mtime}"
    return hashlib.md5(data.encode()).hexdigest()[:10]


def get_cache_dir(input_file: Path) -> Path:
    """ĞŸĞ°Ğ¿ĞºĞ° ĞºĞµÑˆĞ° Ğ´Ğ»Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    h = get_file_hash(input_file)
    cache = CACHE_DIR / f"{input_file.stem}_{h}"
    cache.mkdir(parents=True, exist_ok=True)
    return cache


def load_swears() -> set[str]:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¼Ğ°Ñ‚Ğ°."""
    swears_file = SWEARS_FILE if SWEARS_FILE.exists() else SWEARS_FILE_ALT

    if not swears_file.exists():
        print(f"âŒ Ğ¤Ğ°Ğ¹Ğ» swears.txt Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!")
        print(f"   ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸:")
        print(f"   - {SWEARS_FILE}")
        print(f"   - {SWEARS_FILE_ALT}")
        sys.exit(1)

    swears = set()
    for line in swears_file.read_text(encoding="utf-8").splitlines():
        word = line.strip().lower()
        if word and not word.startswith("#"):
            swears.add(word)

    log(f"ğŸ“ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(swears)} ÑĞ»Ğ¾Ğ² Ğ¸Ğ· {swears_file.name}")
    return swears


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ ĞĞ‘ĞĞ¢Ğ Ğ¡ Ğ’Ğ˜Ğ”Ğ•Ğ/ĞĞ£Ğ”Ğ˜Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_audio_tracks(input_file: Path) -> list[AudioTrack]:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞµĞº."""
    cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_streams", str(input_file)]
    result = run_cmd(cmd, capture=True)

    if result.returncode != 0:
        print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ffprobe")
        sys.exit(1)

    info = json.loads(result.stdout)
    tracks = []
    audio_idx = 0

    for stream in info.get("streams", []):
        if stream.get("codec_type") == "audio":
            tracks.append(AudioTrack(
                stream_index=stream.get("index", 0),
                audio_index=audio_idx,
                codec=stream.get("codec_name", "aac"),
                channels=stream.get("channels", 2),
                sample_rate=int(stream.get("sample_rate", 48000)),
                title=stream.get("tags", {}).get("title", f"Track {audio_idx}")
            ))
            audio_idx += 1

    return tracks


def get_audio_info(input_file: Path) -> Optional[AudioTrack]:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğµ (Ğ´Ğ»Ñ Ñ‡Ğ¸ÑÑ‚Ñ‹Ñ… Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ±ĞµĞ· Ğ²Ğ¸Ğ´ĞµĞ¾)."""
    cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_streams", "-show_format", str(input_file)]
    result = run_cmd(cmd, capture=True)

    if result.returncode != 0:
        return None

    try:
        info = json.loads(result.stdout)
    except (ValueError, KeyError):
        return None

    for stream in info.get("streams", []):
        if stream.get("codec_type") == "audio":
            return AudioTrack(
                stream_index=stream.get("index", 0),
                audio_index=0,
                codec=stream.get("codec_name", "mp3"),
                channels=stream.get("channels", 2),
                sample_rate=int(stream.get("sample_rate", 44100)),
                title=input_file.stem
            )

    return None


def convert_audio_for_whisper(input_file: Path, output_wav: Path,
                               show_progress: bool = False, prefix: str = "") -> bool:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ»ÑĞ±Ğ¾Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ» Ğ² WAV Ğ´Ğ»Ñ Whisper (16kHz mono)."""
    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_file),
        "-ac", "1",           # Ğ¼Ğ¾Ğ½Ğ¾
        "-ar", "16000",       # 16kHz
        "-acodec", "pcm_s16le",
        str(output_wav)
    ]
    if show_progress:
        duration = get_audio_duration(input_file)
        return run_ffmpeg_with_progress(cmd, duration, prefix)
    return run_cmd(cmd, quiet=True).returncode == 0


def convert_audio_full(input_file: Path, output_wav: Path,
                       show_progress: bool = False, prefix: str = "") -> bool:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ» Ğ² WAV Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼."""
    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_file),
        "-acodec", "pcm_f32le",
        str(output_wav)
    ]
    if show_progress:
        duration = get_audio_duration(input_file)
        return run_ffmpeg_with_progress(cmd, duration, prefix)
    return run_cmd(cmd, quiet=True).returncode == 0


def extract_audio(input_file: Path, track: AudioTrack, output_wav: Path,
                  show_progress: bool = False, prefix: str = "") -> bool:
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºÑƒ Ğ² WAV (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ´Ğ»Ñ Whisper)."""
    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_file),
        "-map", f"0:a:{track.audio_index}",
        "-ac", "1",           # Ğ¼Ğ¾Ğ½Ğ¾ (Whisper Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ¼Ğ¾Ğ½Ğ¾)
        "-ar", "16000",       # 16kHz (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Whisper)
        "-acodec", "pcm_s16le",
        str(output_wav)
    ]
    if show_progress:
        duration = get_audio_duration(input_file)
        return run_ffmpeg_with_progress(cmd, duration, prefix)
    return run_cmd(cmd, quiet=True).returncode == 0


def extract_audio_full(input_file: Path, track: AudioTrack, output_wav: Path,
                       show_progress: bool = False, prefix: str = "") -> bool:
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸."""
    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_file),
        "-map", f"0:a:{track.audio_index}",
        "-acodec", "pcm_f32le",  # float32 Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        str(output_wav)
    ]
    if show_progress:
        duration = get_audio_duration(input_file)
        return run_ffmpeg_with_progress(cmd, duration, prefix)
    return run_cmd(cmd, quiet=True).returncode == 0


def is_silent(wav_path: Path) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ñ‚Ğ¸Ñ…Ğ°Ñ Ğ»Ğ¸ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ°."""
    cmd = ["ffmpeg", "-i", str(wav_path), "-af", "volumedetect", "-f", "null", "-"]
    result = subprocess.run(cmd, capture_output=True, text=True)

    for line in result.stderr.split('\n'):
        if 'max_volume' in line:
            try:
                max_vol = float(line.split('max_volume:')[1].split('dB')[0].strip())
                return max_vol < SILENCE_THRESHOLD_DB
            except:
                pass
    return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¢Ğ ĞĞĞ¡ĞšĞ Ğ˜ĞŸĞ¦Ğ˜Ğ¯ (FASTER-WHISPER)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_whisper_model(model_name: str):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper Ñ CUDA (Ğ±ĞµĞ· Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ)."""
    global WhisperModel
    if WhisperModel is None:
        from faster_whisper import WhisperModel as WM
        WhisperModel = WM

    models_dir = CACHE_DIR / "models"
    models_dir.mkdir(parents=True, exist_ok=True)

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾
    local_model = models_dir / f"models--Systran--faster-whisper-{model_name}"
    if local_model.exists():
        log(f"ğŸ¤– Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ {model_name} (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ, CUDA float16)...")
    else:
        log(f"ğŸ¤– Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ {model_name} (CUDA float16)...")

    return WhisperModel(
        model_name,
        device="cuda",
        compute_type="float16",
        download_root=str(models_dir),
        local_files_only=local_model.exists()  # Ğ½Ğµ Ğ»ĞµĞ·Ñ‚ÑŒ Ğ² ÑĞµÑ‚ÑŒ, ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞµÑÑ‚ÑŒ
    )

def transcribe(model, audio_path: Path, language: str = "ru", show_progress: bool = True) -> list[dict]:
    """Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ word-level timestamps Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¾Ğ¼."""
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°
    duration = get_audio_duration(audio_path) if show_progress else 0

    segments, info = model.transcribe(
        str(audio_path),
        language=language,
        word_timestamps=True,
        vad_filter=True,  # Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹ â€” ÑƒÑĞºĞ¾Ñ€ÑĞµÑ‚
        vad_parameters=dict(
            min_silence_duration_ms=500,
            speech_pad_ms=200
        )
    )

    words = []
    for segment in segments:
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ
        if show_progress and duration > 0:
            print_progress(segment.end, duration, "      ğŸ¤ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ")

        if segment.words:
            for word in segment.words:
                words.append({
                    "word": word.word.strip(),
                    "start": word.start,
                    "end": word.end
                })

    return words


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞĞ˜Ğ¡Ğš ĞœĞĞ¢Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_swears(words: list[dict], swears: set[str]) -> list[SwearMatch]:
    """ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ² Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸."""
    matches = []

    # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ regex Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ° Ğ¸Ğ· ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ
    # Ğ£Ñ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ñ‹ ÑĞ»Ğ¾Ğ²Ğ° (Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ğ½Ğ¸Ñ)
    patterns = []
    for swear in swears:
        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ + Ğ»ÑĞ±Ñ‹Ğµ Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ğ½Ğ¸Ñ
        pattern = re.escape(swear)
        patterns.append(pattern)

    combined_pattern = re.compile(
        r'\b(' + '|'.join(patterns) + r')[Ğ°-ÑÑ‘a-z]*\b',
        re.IGNORECASE
    )

    for w in words:
        clean_word = re.sub(r'[^\w]', '', w["word"].lower())
        if combined_pattern.search(clean_word):
            matches.append(SwearMatch(
                start=max(0, w["start"] - PADDING_MS / 1000),
                end=w["end"] + PADDING_MS / 1000,
                word=w["word"]
            ))

    return matches


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ ĞĞ£Ğ”Ğ˜Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_beep(duration_sec: float, sample_rate: int, channels: int) -> np.ndarray:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ¸Ğ¿ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸."""
    t = np.linspace(0, duration_sec, int(sample_rate * duration_sec), dtype=np.float32)
    beep = 0.5 * np.sin(2 * np.pi * BEEP_FREQ * t)

    # Fade in/out Ğ´Ğ»Ñ Ğ¿Ğ»Ğ°Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
    fade_samples = min(int(0.01 * sample_rate), len(beep) // 4)
    if fade_samples > 0:
        beep[:fade_samples] *= np.linspace(0, 1, fade_samples)
        beep[-fade_samples:] *= np.linspace(1, 0, fade_samples)

    if channels > 1:
        beep = np.tile(beep.reshape(-1, 1), (1, channels))

    return beep


def censor_audio(audio_path: Path, output_path: Path, matches: list[SwearMatch],
                 sample_rate: int, channels: int, use_beep: bool = False,
                 show_progress: bool = True) -> int:
    """ĞĞ°ĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ†ĞµĞ½Ğ·ÑƒÑ€Ñƒ Ğ½Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾."""
    import soundfile as sf

    # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾
    audio, sr = sf.read(str(audio_path), dtype='float32')

    if audio.ndim == 1:
        audio = audio.reshape(-1, 1)
        actual_channels = 1
    else:
        actual_channels = audio.shape[1]

    censored_count = 0
    total_matches = len(matches)

    for i, match in enumerate(matches):
        if show_progress and total_matches > 10:
            print_progress(i + 1, total_matches, "      ğŸ”‡ Ğ¦ĞµĞ½Ğ·ÑƒÑ€Ğ°")

        start_sample = int(match.start * sr)
        end_sample = int(match.end * sr)

        # Ğ“Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
        start_sample = max(0, start_sample)
        end_sample = min(len(audio), end_sample)

        if start_sample >= end_sample:
            continue

        duration = (end_sample - start_sample) / sr

        if use_beep:
            beep = generate_beep(duration, sr, actual_channels)
            if len(beep) != end_sample - start_sample:
                beep = np.resize(beep, (end_sample - start_sample, actual_channels))
            audio[start_sample:end_sample] = beep
        else:
            # Ğ¢Ğ¸ÑˆĞ¸Ğ½Ğ°
            audio[start_sample:end_sample] = 0

        censored_count += 1

    # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼
    if actual_channels == 1:
        audio = audio.flatten()

    sf.write(str(output_path), audio, sr, subtype='FLOAT')

    return censored_count


def encode_audio(input_wav: Path, output_file: Path, track: AudioTrack,
                 show_progress: bool = False, prefix: str = "") -> bool:
    """ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ WAV Ğ² Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚."""
    codec_map = {
        "aac": ["-c:a", "aac", "-b:a", "192k"],
        "mp3": ["-c:a", "libmp3lame", "-b:a", "192k"],
        "opus": ["-c:a", "libopus", "-b:a", "128k"],
        "vorbis": ["-c:a", "libvorbis", "-b:a", "192k"],
        "flac": ["-c:a", "flac"],
        "ac3": ["-c:a", "ac3", "-b:a", "384k"],
        "eac3": ["-c:a", "eac3", "-b:a", "384k"],
        "dts": ["-c:a", "dca", "-b:a", "768k"],
    }

    codec_args = codec_map.get(track.codec, ["-c:a", "aac", "-b:a", "192k"])

    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_wav),
        "-ar", str(track.sample_rate),
        "-ac", str(track.channels),
        *codec_args,
        str(output_file)
    ]

    if show_progress:
        duration = get_audio_duration(input_wav)
        return run_ffmpeg_with_progress(cmd, duration, prefix)
    return run_cmd(cmd, quiet=True).returncode == 0


def copy_audio_track(input_file: Path, track: AudioTrack, output_file: Path) -> bool:
    """ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºÑƒ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹."""
    cmd = [
        "ffmpeg", "-y", "-hide_banner", "-loglevel", "error",
        "-i", str(input_file),
        "-map", f"0:a:{track.audio_index}",
        "-c:a", "copy",
        str(output_file)
    ]
    return run_cmd(cmd, quiet=True).returncode == 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ‘ĞĞ ĞšĞ Ğ’Ğ˜Ğ”Ğ•Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def assemble_video(input_file: Path, audio_files: list[Path],
                   output_file: Path, tracks: list[AudioTrack]) -> bool:
    """Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾."""
    cmd = ["ffmpeg", "-y", "-hide_banner", "-loglevel", "warning", "-stats",
           "-i", str(input_file)]

    for audio in audio_files:
        cmd.extend(["-i", str(audio)])

    # ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³: Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹ Ğ¸Ğ· Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğ°, Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ· Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ…
    cmd.extend(["-map", "0:v?"])

    for i in range(len(audio_files)):
        cmd.extend(["-map", f"{i+1}:a:0"])

    cmd.extend(["-map", "0:s?"])  # ÑÑƒĞ±Ñ‚Ğ¸Ñ‚Ñ€Ñ‹
    cmd.extend(["-c:v", "copy", "-c:s", "copy", "-c:a", "copy"])

    # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞµĞº
    for i, track in enumerate(tracks):
        if track.title:
            cmd.extend([f"-metadata:s:a:{i}", f"title={track.title}"])

    cmd.append(str(output_file))

    return run_cmd(cmd, quiet=False).returncode == 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_track(model, input_file: Path, track: AudioTrack, cache_dir: Path,
                  swears: set[str], use_beep: bool) -> tuple[Path, int]:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ´Ğ½Ñƒ Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºÑƒ."""

    idx = track.audio_index

    # ĞŸÑƒÑ‚Ğ¸
    wav_whisper = cache_dir / f"track_{idx}_16k.wav"
    wav_full = cache_dir / f"track_{idx}_full.wav"
    wav_censored = cache_dir / f"track_{idx}_censored.wav"
    final_audio = cache_dir / f"track_{idx}_final.mka"
    transcript_cache = cache_dir / f"track_{idx}_transcript.json"
    skip_marker = cache_dir / f"track_{idx}_skip"

    # Ğ£Ğ¶Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾?
    if final_audio.exists():
        log(f"ğŸ’¾ ĞšĞµÑˆ", prefix="      ")
        return final_audio, -1  # -1 = Ğ¸Ğ· ĞºĞµÑˆĞ°

    # ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ° Ñ€Ğ°Ğ½ĞµĞµ?
    if skip_marker.exists():
        log(f"ğŸ”‡ Ğ¢Ğ¸Ñ…Ğ°Ñ (ĞºĞµÑˆ)", prefix="      ")
        if not final_audio.exists():
            copy_audio_track(input_file, track, final_audio)
        return final_audio, 0

    # 1. Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ´Ğ»Ñ Whisper (16kHz mono)
    if not wav_whisper.exists():
        log(f"ğŸ“¤ Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ...", prefix="      ")
        if not extract_audio(input_file, track, wav_whisper):
            raise RuntimeError("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ")

    # 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñƒ
    if is_silent(wav_whisper):
        log(f"ğŸ”‡ Ğ¢Ğ¸Ñ…Ğ°Ñ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ°", prefix="      ")
        skip_marker.touch()
        copy_audio_track(input_file, track, final_audio)
        return final_audio, 0

    # 3. Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
    words = []
    if transcript_cache.exists():
        log(f"ğŸ“ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ¸Ğ· ĞºĞµÑˆĞ°", prefix="      ")
        words = json.loads(transcript_cache.read_text(encoding="utf-8"))
    else:
        log(f"ğŸ¤ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ...", prefix="      ")
        words = transcribe(model, wav_whisper)
        transcript_cache.write_text(json.dumps(words, ensure_ascii=False), encoding="utf-8")

    # 4. ĞŸĞ¾Ğ¸ÑĞº Ğ¼Ğ°Ñ‚Ğ°
    matches = find_swears(words, swears)
    log(f"ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(matches)} ÑĞ»Ğ¾Ğ²", prefix="      ")

    if not matches:
        # ĞĞµÑ‚ Ğ¼Ğ°Ñ‚Ğ° â€” ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
        copy_audio_track(input_file, track, final_audio)
        return final_audio, 0

    # 5. Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
    if not wav_full.exists():
        log(f"ğŸ“¤ Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ (Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)...", prefix="      ")
        if not extract_audio_full(input_file, track, wav_full):
            raise RuntimeError("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ")

    # 6. Ğ¦ĞµĞ½Ğ·ÑƒÑ€Ğ¸Ğ¼
    log(f"ğŸ”‡ Ğ¦ĞµĞ½Ğ·ÑƒÑ€Ğ°...", prefix="      ")
    censored = censor_audio(wav_full, wav_censored, matches,
                            track.sample_rate, track.channels, use_beep)

    # 7. ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾
    log(f"ğŸ”„ ĞšĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ({track.codec})...", prefix="      ")
    if not encode_audio(wav_censored, final_audio, track):
        raise RuntimeError("ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ")

    return final_audio, censored


def process_audio_file(input_file: Path, output_file: Path, model,
                       swears: set[str], use_beep: bool) -> bool:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ» (Ğ±ĞµĞ· Ğ²Ğ¸Ğ´ĞµĞ¾)."""

    print(f"\nğŸµ Ğ’Ñ…Ğ¾Ğ´:  {input_file}")
    print(f"ğŸ“ Ğ’Ñ‹Ñ…Ğ¾Ğ´: {output_file}")
    print()

    # ĞšĞµÑˆ
    cache_dir = get_cache_dir(input_file)
    log(f"ğŸ’¾ ĞšĞµÑˆ: {cache_dir}")

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°ÑƒĞ´Ğ¸Ğ¾
    audio_info = get_audio_info(input_file)
    if not audio_info:
        print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»!")
        return False

    print(f"ğŸ“Š {audio_info.codec}, {audio_info.channels}ch, {audio_info.sample_rate}Hz")

    # ĞŸÑƒÑ‚Ğ¸
    wav_whisper = cache_dir / "audio_16k.wav"
    wav_full = cache_dir / "audio_full.wav"
    wav_censored = cache_dir / "audio_censored.wav"
    transcript_cache = cache_dir / "transcript.json"

    # 1. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ Whisper (16kHz mono)
    if not wav_whisper.exists():
        log("ğŸ“¤ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸...")
        if not convert_audio_for_whisper(input_file, wav_whisper,
                                         show_progress=True, prefix="   ğŸ“¤ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ"):
            print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸")
            return False

    # 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñƒ
    if is_silent(wav_whisper):
        log("ğŸ”‡ Ğ¢Ğ¸Ñ…Ğ¸Ğ¹ Ñ„Ğ°Ğ¹Ğ» â€” ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ")
        shutil.copy(input_file, output_file)
        return True

    # 3. Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
    words = []
    if transcript_cache.exists():
        log("ğŸ“ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ¸Ğ· ĞºĞµÑˆĞ°")
        words = json.loads(transcript_cache.read_text(encoding="utf-8"))
    else:
        log("ğŸ¤ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ...")
        words = transcribe(model, wav_whisper)
        transcript_cache.write_text(json.dumps(words, ensure_ascii=False), encoding="utf-8")

    # 4. ĞŸĞ¾Ğ¸ÑĞº Ğ¼Ğ°Ñ‚Ğ°
    matches = find_swears(words, swears)
    log(f"ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(matches)} ÑĞ»Ğ¾Ğ²")

    if not matches:
        log("âœ… ĞœĞ°Ñ‚Ğ° Ğ½ĞµÑ‚ â€” ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ")
        shutil.copy(input_file, output_file)
        return True

    # 5. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
    if not wav_full.exists():
        log("ğŸ“¤ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ (Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)...")
        if not convert_audio_full(input_file, wav_full,
                                  show_progress=True, prefix="   ğŸ“¤ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ"):
            print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸")
            return False

    # 6. Ğ¦ĞµĞ½Ğ·ÑƒÑ€Ğ¸Ğ¼
    log("ğŸ”‡ Ğ¦ĞµĞ½Ğ·ÑƒÑ€Ğ°...")
    censored = censor_audio(wav_full, wav_censored, matches,
                            audio_info.sample_rate, audio_info.channels, use_beep)

    # 7. ĞšĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
    log(f"ğŸ”„ ĞšĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ({audio_info.codec})...")
    if not encode_audio(wav_censored, output_file, audio_info,
                        show_progress=True, prefix="   ğŸ”„ ĞšĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ"):
        print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ")
        return False

    print(f"\n{'â•'*50}")
    print("âœ… Ğ“ĞĞ¢ĞĞ’Ğ!")
    print(f"ğŸ“ {output_file}")
    print(f"ğŸ”‡ Ğ—Ğ°Ñ†ĞµĞ½Ğ·ÑƒÑ€ĞµĞ½Ğ¾: {censored} ÑĞ»Ğ¾Ğ²")
    print('â•'*50)

    return True


def process_video_file(input_file: Path, output_file: Path, model,
                       swears: set[str], track_filter: Optional[list[int]],
                       use_beep: bool) -> bool:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»."""

    print(f"\nğŸ¬ Ğ’Ñ…Ğ¾Ğ´:  {input_file}")
    print(f"ğŸ“ Ğ’Ñ‹Ñ…Ğ¾Ğ´: {output_file}")
    print()

    # ĞšĞµÑˆ
    cache_dir = get_cache_dir(input_file)
    log(f"ğŸ’¾ ĞšĞµÑˆ: {cache_dir}")

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸
    tracks = get_audio_tracks(input_file)
    if not tracks:
        print("âŒ ĞÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹!")
        return False

    print(f"\nğŸ“Š ĞÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞµĞº: {len(tracks)}")
    for t in tracks:
        print(f"   [{t.audio_index}] {t.title} ({t.codec}, {t.channels}ch, {t.sample_rate}Hz)")

    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€
    if track_filter:
        tracks = [t for t in tracks if t.audio_index in track_filter]
        print(f"\nâš™ï¸  Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ñ‹ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸: {track_filter}")

    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸
    processed_files = []
    total_censored = 0

    for i, track in enumerate(tracks, 1):
        print(f"\n{'â”€'*50}")
        print(f"ğŸµ [{i}/{len(tracks)}] Ğ”Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ° {track.audio_index}: {track.title}")

        try:
            audio_file, censored = process_track(
                model, input_file, track, cache_dir, swears, use_beep
            )
            processed_files.append(audio_file)
            if censored > 0:
                total_censored += censored
                log(f"âœ… Ğ—Ğ°Ñ†ĞµĞ½Ğ·ÑƒÑ€ĞµĞ½Ğ¾: {censored}", prefix="      ")
            elif censored == 0:
                log("âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ (Ğ¼Ğ°Ñ‚Ğ° Ğ½ĞµÑ‚)", prefix="      ")
            else:
                log("âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ (Ğ¸Ğ· ĞºĞµÑˆĞ°)", prefix="      ")
        except Exception as e:
            print(f"      âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            return False

    # Ğ¡Ğ±Ğ¾Ñ€ĞºĞ°
    print(f"\n{'â”€'*50}")
    print("ğŸ“¦ Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾...")

    if not assemble_video(input_file, processed_files, output_file, tracks):
        print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ±Ğ¾Ñ€ĞºĞ¸")
        return False

    print(f"\n{'â•'*50}")
    print("âœ… Ğ“ĞĞ¢ĞĞ’Ğ!")
    print(f"ğŸ“ {output_file}")
    print(f"ğŸ”‡ Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ñ†ĞµĞ½Ğ·ÑƒÑ€ĞµĞ½Ğ¾: {total_censored} ÑĞ»Ğ¾Ğ²")
    print('â•'*50)

    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ñ†ĞµĞ½Ğ·ÑƒÑ€Ğ° Ğ¼Ğ°Ñ‚Ğ° Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾ (GPU)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
  %(prog)s video.mkv                    # Ğ²Ğ¸Ğ´ĞµĞ¾, Ğ²ÑĞµ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ medium
  %(prog)s podcast.mp3                  # Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»
  %(prog)s *.mkv *.mp3                  # Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
  %(prog)s video.mkv -m large-v3        # Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ, Ğ½Ğ¾ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½ĞµĞµ
  %(prog)s video.mkv -t 0,2             # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸ 0 Ğ¸ 2
  %(prog)s video.mkv --beep             # Ğ±Ğ¸Ğ¿ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹
  %(prog)s video.mkv --info             # Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸
  %(prog)s --clear-cache                # Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²ĞµÑÑŒ ĞºĞµÑˆ
        """
    )

    parser.add_argument("input", nargs="*", help="Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ (Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ»Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾)")
    parser.add_argument("-o", "--output", help="Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾)")
    parser.add_argument("-m", "--model", default=DEFAULT_MODEL,
                        help=f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Whisper (default: {DEFAULT_MODEL})")
    parser.add_argument("-t", "--tracks", help="Ğ”Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 0,2,4)")
    parser.add_argument("--beep", action="store_true", help="Ğ‘Ğ¸Ğ¿ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹")
    parser.add_argument("--info", action="store_true", help="ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞ¸")
    parser.add_argument("--clear-cache", action="store_true", help="ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ ĞºĞµÑˆ (Ğ±ĞµĞ· Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)")
    parser.add_argument("--clear-models", action="store_true", help="ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    args = parser.parse_args()

    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ĞºĞµÑˆĞ° (Ğ±ĞµĞ· Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)
    if args.clear_cache:
        if CACHE_DIR.exists():
            models_dir = CACHE_DIR / "models"
            for item in CACHE_DIR.iterdir():
                if item == models_dir:
                    continue
                if item.is_dir():
                    shutil.rmtree(item)
                else:
                    item.unlink()
            print(f"ğŸ—‘ï¸  ĞšĞµÑˆ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½ (Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹): {CACHE_DIR}")
        else:
            print("ĞšĞµÑˆ Ğ¿ÑƒÑÑ‚")
        return

    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    if args.clear_models:
        models_dir = CACHE_DIR / "models"
        if models_dir.exists():
            shutil.rmtree(models_dir)
            print(f"ğŸ—‘ï¸  ĞœĞ¾Ğ´ĞµĞ»Ğ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ñ‹: {models_dir}")
        else:
            print("ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹")
        return

    if not args.input:
        parser.print_help()
        return

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    input_files = []
    for pattern in args.input:
        path = Path(pattern).resolve()
        if path.exists():
            input_files.append(path)
        else:
            print(f"âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {path}")

    if not input_files:
        print("âŒ ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸!")
        sys.exit(1)

    # Ğ˜Ğ½Ñ„Ğ¾ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°)
    if args.info:
        for input_path in input_files:
            print(f"\nğŸ“ {input_path}")
            if is_audio_file(input_path):
                info = get_audio_info(input_path)
                if info:
                    print(f"    ğŸµ ĞÑƒĞ´Ğ¸Ğ¾: {info.codec}, {info.channels}ch, {info.sample_rate}Hz")
            else:
                tracks = get_audio_tracks(input_path)
                for t in tracks:
                    print(f"    [{t.audio_index}] {t.title}")
                    print(f"        {t.codec}, {t.channels}ch, {t.sample_rate}Hz")
        return

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° -o Ğ¿Ñ€Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…
    if args.output and len(input_files) > 1:
        print("âŒ ĞĞ¿Ñ†Ğ¸Ñ -o/--output Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ¼!")
        sys.exit(1)

    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞµĞº
    track_filter = None
    if args.tracks:
        track_filter = [int(x.strip()) for x in args.tracks.split(",")]

    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·
    swears = load_swears()
    print(f"\nğŸ¤– ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {args.model}")
    model = load_whisper_model(args.model)

    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    results = []
    total_files = len(input_files)

    for i, input_path in enumerate(input_files, 1):
        if total_files > 1:
            print(f"\n{'â•'*60}")
            print(f"ğŸ“‚ Ğ¤Ğ°Ğ¹Ğ» [{i}/{total_files}]: {input_path.name}")
            print('â•'*60)

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿ÑƒÑ‚ÑŒ
        if args.output and total_files == 1:
            output_path = Path(args.output).resolve()
        else:
            output_path = input_path.parent / f"{input_path.stem}_censored{input_path.suffix}"

        # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‚Ğ¸Ğ¿Ğ°
        if is_audio_file(input_path):
            success = process_audio_file(input_path, output_path, model, swears, args.beep)
        else:
            success = process_video_file(input_path, output_path, model, swears,
                                         track_filter, args.beep)

        results.append((input_path, success))

    # Ğ˜Ñ‚Ğ¾Ğ³Ğ¸ Ğ¿Ñ€Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…
    if total_files > 1:
        print(f"\n{'â•'*60}")
        print("ğŸ“Š Ğ˜Ğ¢ĞĞ“Ğ˜:")
        print('â•'*60)
        success_count = sum(1 for _, s in results if s)
        for path, success in results:
            status = "âœ…" if success else "âŒ"
            print(f"  {status} {path.name}")
        print(f"\n  Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾: {success_count}/{total_files}")

    # ĞšĞ¾Ğ´ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°
    all_success = all(s for _, s in results)
    sys.exit(0 if all_success else 1)


if __name__ == "__main__":
    main()
